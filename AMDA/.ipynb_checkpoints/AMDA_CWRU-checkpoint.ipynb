{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time \n",
    "from torch.autograd import grad\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import scipy.io\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device('cuda')\n",
    "seed = 999\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_AMDA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder_AMDA, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # first layer  4096*1-->  1017*8\n",
    "            nn.Conv1d(1, 8, kernel_size=32,stride=2, padding=1),\n",
    "#             nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # second layer  1017*8-->  250*16\n",
    "            nn.Conv1d(8, 16, kernel_size=16,stride=2, padding=1),\n",
    "#             nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # third layer  250*16-->  60*32\n",
    "            nn.Conv1d(16, 32, kernel_size=8,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2), \n",
    "            # fourth layer 60*32--> 14*32\n",
    "            nn.Conv1d(32, 32, kernel_size=8,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # fifth layer 14*32--> 3*64\n",
    "            nn.Conv1d(32, 64, kernel_size=3,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2))\n",
    "         # flatenning wit fully connected layers\n",
    "        \n",
    "        self.fc1 = nn.Linear(64*3, 256)# optimal when 0 source domain\n",
    "\n",
    "    def forward(self, input):\n",
    "        conv_out = self.encoder(input)\n",
    "#         conv_out=F.dropout(conv_out)# we didn't need it when source domain is zero condition\n",
    "        feat = self.fc1(conv_out.view(conv_out.shape[0],-1))\n",
    "        return feat\n",
    "            \n",
    "    \"\"\"classifier model for AMDA.\"\"\"\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc2 = nn.Linear(256, 10) #this with 0 as souce it give optimal results \n",
    "  \n",
    "\n",
    "    def forward(self, feat):\n",
    "        out = F.dropout(F.relu(feat), training=self.training)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator model for source domain.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_dims, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, output_dims),\n",
    "            nn.LogSoftmax())\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        out = self.layer(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWRU Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 0\n",
    "source_data=torch.load('./data/source_data_4096.pt')\n",
    "source_labels_0=torch.load('./data/source_labels_4096.pt')\n",
    "test_data_0=torch.load('./data/test_data_4096.pt')\n",
    "test_labels_0=torch.load('./data/test_labels_4096.pt')\n",
    "# load 1\n",
    "target_data_a=torch.load('./data/target_data_a_4096.pt')\n",
    "target_labels_a=torch.load('./data/target_labels_a_4096.pt')\n",
    "test_a=torch.load('./data/test_data_a_4096.pt')\n",
    "test_a_labels=torch.load('./data/test_labels_a_4096.pt')\n",
    "# load 2\n",
    "target_data_b=torch.load('./data/target_data_b_4096.pt')\n",
    "target_labels_b=torch.load('./data/target_labels_b_4096.pt')\n",
    "test_b=torch.load('./data/test_data_b_4096.pt')\n",
    "test_b_labels=torch.load('./data/test_labels_b_4096.pt')\n",
    "# load 3\n",
    "target_data_c=torch.load('./data/target_data_c_4096.pt')\n",
    "target_labels_c=torch.load('./data/target_labels_c_4096.pt')\n",
    "test_c=torch.load('./data/test_data_c_4096.pt')\n",
    "test_c_labels=torch.load('./data/test_labels_c_4096.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing differnt source and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "4096\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "source_domain=source_data.float()\n",
    "source_labels=source_labels_0.long()\n",
    "# testing on same distribution \n",
    "test_data=test.float()\n",
    "test_labels=test_b_labels.long()\n",
    "\n",
    "#Testing on differnt domain \n",
    "target_domain_0=target_data_a.float()\n",
    "target_labels_0=target_labels_a.long()\n",
    "target_domain_1=target_data_b.float()\n",
    "target_labels_1=target_labels_b.long()\n",
    "target_domain_2=target_data_c.float()\n",
    "target_labels_2=target_labels_c.long()\n",
    "\n",
    "\n",
    "sample_length=source_data.size(1)\n",
    "num_samples=source_data.size(0)\n",
    "num_test_samples=test_data.size(0)\n",
    "print(num_test_samples)\n",
    "print(sample_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Params for AMDA.\"\"\"\n",
    "d_input_dims = 256 \n",
    "d_hidden_dims = 256 \n",
    "d_output_dims = 2\n",
    "# params for training network\n",
    "num_epochs_pre = 100\n",
    "log_step_pre = 10\n",
    "eval_step_pre = 20\n",
    "save_step_pre = 100\n",
    "num_epochs = 150\n",
    "log_step = 10\n",
    "save_step = 100\n",
    "# params for optimizing models\n",
    "d_learning_rate = 1e-4\n",
    "c_learning_rate = 1e-4\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "bs=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_src(encoder, classifier):\n",
    "    \"\"\"Train classifier for source domain.\"\"\"\n",
    "    ####################\n",
    "    # 1. setup network #\n",
    "    ####################\n",
    "    # set train state for Dropout and BN layers\n",
    "    src_encoder.train()\n",
    "    classifier.train()\n",
    "\n",
    "    # setup criterion and optimizer\n",
    "    optimizer = optim.Adam(\n",
    "        list(encoder.parameters()) + list(classifier.parameters()),\n",
    "        lr=c_learning_rate,\n",
    "        betas=(beta1, beta2))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    ####################\n",
    "    # 2. train network #\n",
    "    ####################\n",
    "\n",
    "    for epoch in range(num_epochs_pre):\n",
    "        running_loss=0\n",
    "        running_accuracy=0\n",
    "        num_batches=0\n",
    "        for step in range(0,num_samples,bs):\n",
    "            # training on target domain_a as a source\n",
    "            minibatch_data =  source_domain[step:step+bs].unsqueeze(dim=1)\n",
    "            minibatch_label=  source_labels[step:step+bs].squeeze()\n",
    "            minibatch_data=minibatch_data.to(device)\n",
    "            minibatch_label=minibatch_label.to(device)\n",
    "    \n",
    "            # zero gradients for optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # compute loss for critic\n",
    "            preds =classifier (encoder(minibatch_data))\n",
    "            loss = criterion(preds, minibatch_label)\n",
    "            \n",
    "            # optimize source classifier\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach().item()\n",
    "        \n",
    "            running_accuracy += (preds.max(1)[1] == minibatch_label).float().mean().item()\n",
    "            num_batches+=1\n",
    "        # print epoch info\n",
    "        if ((epoch) % log_step_pre == 0):\n",
    "            print(\"Epoch [{}/{}] : loss={} train_accuracy={}\"\n",
    "                  .format(epoch,\n",
    "                          num_epochs_pre,\n",
    "                          running_loss/num_batches,\n",
    "                        running_accuracy*100/num_batches ))\n",
    "\n",
    "        # eval model on test set\n",
    "        if ((epoch + 1) % eval_step_pre == 0):\n",
    "            eval_src(encoder, classifier)\n",
    "\n",
    "        # save model parameters\n",
    "        if ((epoch + 1) % save_step_pre == 0):\n",
    "            torch.save(encoder.state_dict(), 'M_T_src_encoder-{}.pt'.format(epoch + 1))\n",
    "            torch.save(classifier.state_dict(), 'M_T_src-classifier-{}.pt'.format(epoch + 1))\n",
    "\n",
    "    # # save final model\n",
    "    torch.save(encoder.state_dict(), 'M_T_src-encoder-final.pt')\n",
    "    torch.save(classifier.state_dict(), 'M_T_src-classifier-final.pt')\n",
    "\n",
    "    return encoder, classifier\n",
    "def eval_src(encoder, classifier):\n",
    "    \"\"\"Evaluate classifier for source domain.\"\"\"\n",
    "    # set eval state for Dropout and BN layers\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    # init loss and accuracy\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    num_batches=0\n",
    "    # set loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for i in range(0,num_test_samples,bs):\n",
    "        minibatch_data =  test_data[i:i+bs].unsqueeze(dim=1)\n",
    "        minibatch_label= test_labels[i:i+bs].squeeze()\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        scores=classifier(encoder(minibatch_data))\n",
    "        \n",
    "        # calculate accuracy\n",
    "                               \n",
    "        acc += (scores.max(1)[1] == minibatch_label).float().mean().item()\n",
    "        loss += criterion(scores, minibatch_label)\n",
    "        num_batches+=1\n",
    "    mean_accuracy = acc / num_batches\n",
    "#     acc_plt.append(mean_accuracy)\n",
    "    mean_loss = loss / num_batches\n",
    "#     loss_plt.append(mean_loss)\n",
    "    print(\"Avg Loss = {}, Avg Accuracy = {:2%}\".format(mean_loss, mean_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tgt(src_encoder, tgt_encoder, critic):\n",
    "    \"\"\"Train encoder for target domain.\"\"\"\n",
    "    ####################\n",
    "    # 1. setup network #\n",
    "    ####################\n",
    "\n",
    "    # set train state for Dropout and BN layers\n",
    "    tgt_encoder.train()\n",
    "    critic.train()\n",
    "\n",
    "    # setup criterion and optimizer\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_tgt = optim.Adam(tgt_encoder.parameters(),\n",
    "                               lr=c_learning_rate,\n",
    "                               betas=(beta1, beta2))\n",
    "    optimizer_critic = optim.Adam(critic.parameters(),\n",
    "                                  lr=d_learning_rate,\n",
    "                                  betas=(beta1, beta2))\n",
    "    len_data_loader =num_samples\n",
    "\n",
    "    ####################\n",
    "    # 2. train network #\n",
    "    ####################\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # initilize loss\n",
    "        run_critic_loss=0\n",
    "        acc=0\n",
    "        run_tgt_loss=0\n",
    "        num_batches=0\n",
    "        for i in range(0,num_samples,bs):\n",
    "            ###########################\n",
    "            # 2.1 train discriminator #\n",
    "            ###########################\n",
    "\n",
    "            # make images variable\n",
    "            sample_src= source_domain[i:i+bs].float().unsqueeze(dim=1).to(device)\n",
    "            sample_tgt_1=target_domain_0[i:i+bs].float().unsqueeze(dim=1).to(device)\n",
    "            sample_tgt_2=target_domain_1[i:i+bs].float().unsqueeze(dim=1).to(device)\n",
    "            sample_tgt_3=target_domain_2[i:i+bs].float().unsqueeze(dim=1).to(device)\n",
    "            # zero gradients for optimizer\n",
    "            optimizer_critic.zero_grad()\n",
    "\n",
    "            # extract and concat features\n",
    "            feat_src = src_encoder(sample_src)\n",
    "            feat_tgt_1 = tgt_encoder(sample_tgt_1)\n",
    "            feat_tgt_2 = tgt_encoder(sample_tgt_2)\n",
    "            feat_tgt_3 = tgt_encoder(sample_tgt_3)\n",
    "            feat_tgt= torch.cat((feat_tgt_1,feat_tgt_2),0)\n",
    "#             feat_tgt= torch.cat((feat_tgt_1,feat_tgt_2,feat_tgt_3),0)\n",
    "\n",
    "            feat_concat = torch.cat((feat_src, feat_tgt), 0)\n",
    "            # predict on discriminator\n",
    "            pred_concat = critic(feat_concat.detach()).to(device)\n",
    "\n",
    "            # prepare real and fake label\n",
    "            label_src =Variable(torch.ones(feat_src.size(0)).long())\n",
    "            label_tgt = Variable(torch.zeros(feat_tgt.size(0)).long())\n",
    "            label_concat = torch.cat((label_src, label_tgt), 0).to(device)\n",
    "\n",
    "            # compute loss for critic\n",
    "            loss_critic = criterion(pred_concat, label_concat)\n",
    "            loss_critic.backward()\n",
    "\n",
    "            # optimize critic\n",
    "            optimizer_critic.step()\n",
    "\n",
    "            pred_cls = torch.squeeze(pred_concat.max(1)[1])\n",
    "            acc += (pred_cls == label_concat).float().mean()\n",
    "            run_critic_loss+=  loss_critic.detach().item()\n",
    "            ############################\n",
    "            # 2.2 train target encoder #\n",
    "            ############################\n",
    "            optimizer_tgt.zero_grad() # edited here becareful \n",
    "            for i in range (2):\n",
    "                # extract and target features\n",
    "                feat_tgt_1 = tgt_encoder(sample_tgt_1)\n",
    "                feat_tgt_2 = tgt_encoder(sample_tgt_2)\n",
    "                feat_tgt_3 = tgt_encoder(sample_tgt_3)\n",
    "                feat_tgt= torch.cat((feat_tgt_1,feat_tgt_2,feat_tgt_3),0)\n",
    "\n",
    "                # predict on discriminator\n",
    "                pred_tgt = critic(feat_tgt).to(device)\n",
    "\n",
    "                # prepare fake labels to enforce the feature extractor to confuse the critic \n",
    "                label_tgt = Variable(torch.ones(feat_tgt.size(0)).long()).to(device)\n",
    "\n",
    "                # compute loss for target encoder\n",
    "                loss_tgt = criterion(pred_tgt, label_tgt)\n",
    "                loss_tgt.backward()\n",
    "\n",
    "                # optimize target encoder\n",
    "                optimizer_tgt.step()\n",
    "\n",
    "                run_tgt_loss+=loss_tgt.detach().item()\n",
    "            num_batches+=1\n",
    "        #######################\n",
    "        # 2.3 print epoch info #\n",
    "        #######################\n",
    "        if ((epoch) % log_step == 0):\n",
    "            print(\"Epoch [{}/{}] :\"\n",
    "                  \"discriminator_loss={:.5f} target_loss={:.5f} discriminator_acc={:.5f}\"\n",
    "                  .format(epoch,\n",
    "                         num_epochs,\n",
    "                          run_critic_loss/num_batches,\n",
    "                          run_tgt_loss/(num_batches*5),\n",
    "                          acc.data[0]/num_batches))\n",
    "            print(\"=== Evaluating classifier for encoded target domain ===\")\n",
    "            print(\">>> source only <<<\")\n",
    "            eval_tgt(src_encoder, src_classifier)\n",
    "            print(\">>> domain adaption <<<\")\n",
    "            eval_tgt(tgt_encoder, src_classifier)\n",
    "\n",
    "\n",
    "        #############################\n",
    "        # 2.4 save model parameters #\n",
    "        #############################\n",
    "        if ((epoch + 1) % save_step == 0):\n",
    "            torch.save(critic.state_dict(),\n",
    "            'M_T_ADDA-critic-{}.pt'.format(epoch + 1))\n",
    "            torch.save(tgt_encoder.state_dict(),\n",
    "                'M_T_ADDA-target-encoder-{}.pt'.format(epoch + 1))\n",
    "\n",
    "    torch.save(critic.state_dict(), 'M_T_ADDA-critic-final.pt')\n",
    "    torch.save(tgt_encoder.state_dict(),'M_T_ADDA-target-encoder-final.pt')\n",
    "    return tgt_encoder\n",
    "\n",
    "\n",
    "\n",
    "def eval_tgt(encoder, classifier):\n",
    "    \"\"\"Evaluation for target encoder by source classifier on target dataset.\"\"\"\n",
    "    # set eval state for Dropout and BN layers\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    # init loss and accuracy\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    num_batches=0\n",
    "    # set loss function\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    x=[]\n",
    "    y=[]\n",
    "    # evaluate network\n",
    "    for i in range(0,num_samples,bs):\n",
    "        minibatch_data =  target_domain[i:i+bs].unsqueeze(dim=1)\n",
    "        minibatch_label= target_labels[i:i+bs].squeeze()\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "#         inputs = (minibatch_data - src_mean)/src_std  \n",
    "#         inputs=inputs.to(device)\n",
    "        preds = classifier(encoder(minibatch_data))\n",
    "        loss += criterion(preds, minibatch_label.squeeze()).data[0]\n",
    "        x.append(preds.max(1)[1])\n",
    "        y.append(minibatch_label)\n",
    "        pred_cls = preds.data.max(1)[1]\n",
    "#         acc += pred_cls.eq(minibatch_label.data).cpu().sum().float()\n",
    "        acc +=(pred_cls == minibatch_label).float().mean()\n",
    "        num_batches+=1\n",
    "    loss /= num_batches\n",
    "    acc /= num_batches\n",
    "    \n",
    "    print(\"Avg Loss = {}, Avg Accuracy = {}\".format(loss, acc*100,'%'))\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Main Code  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training classifier for source domain ===\n",
      ">>> Source Encoder <<<\n",
      "Encoder_ADDA(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv1d(1, 8, kernel_size=(32,), stride=(2,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv1d(8, 16, kernel_size=(16,), stride=(2,), padding=(1,))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv1d(16, 32, kernel_size=(8,), stride=(2,), padding=(1,))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv1d(32, 32, kernel_size=(8,), stride=(2,), padding=(1,))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=192, out_features=256, bias=True)\n",
      ")\n",
      ">>> Source Classifier <<<\n",
      "Classifier(\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [0/100] : loss=1.9750582590699195 train_accuracy=26.187500478699803\n",
      "Epoch [10/100] : loss=0.0037619492094108863 train_accuracy=99.93749998509884\n",
      "Avg Loss = 6.675720101156912e-07, Avg Accuracy = 100.000000%\n",
      "Epoch [20/100] : loss=5.626678450276756e-07 train_accuracy=100.0\n",
      "Epoch [30/100] : loss=0.0 train_accuracy=100.0\n",
      "Avg Loss = 0.0, Avg Accuracy = 100.000000%\n",
      "Epoch [40/100] : loss=0.0 train_accuracy=100.0\n",
      "Epoch [50/100] : loss=0.0 train_accuracy=100.0\n",
      "Avg Loss = 0.0, Avg Accuracy = 100.000000%\n",
      "Epoch [60/100] : loss=0.0 train_accuracy=100.0\n",
      "Epoch [70/100] : loss=0.0 train_accuracy=100.0\n",
      "Avg Loss = 0.0, Avg Accuracy = 100.000000%\n",
      "Epoch [80/100] : loss=0.0 train_accuracy=100.0\n",
      "Epoch [90/100] : loss=0.0 train_accuracy=100.0\n",
      "Avg Loss = 0.0, Avg Accuracy = 100.000000%\n",
      "=== Evaluating classifier for source domain ===\n",
      "Avg Loss = 0.0, Avg Accuracy = 100.000000%\n",
      "=== Training encoder for target domain ===\n",
      ">>> Target Encoder <<<\n",
      "Encoder_ADDA(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv1d(1, 8, kernel_size=(32,), stride=(2,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv1d(8, 16, kernel_size=(16,), stride=(2,), padding=(1,))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv1d(16, 32, kernel_size=(8,), stride=(2,), padding=(1,))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv1d(32, 32, kernel_size=(8,), stride=(2,), padding=(1,))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=192, out_features=256, bias=True)\n",
      ")\n",
      ">>> Critic <<<\n",
      "Discriminator(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=2, bias=True)\n",
      "    (5): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedragab1992/miniconda3/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/home/mohamedragab1992/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:115: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/mohamedragab1992/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:161: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/150] :discriminator_loss=0.99515 target_loss=0.32004 discriminator_acc=0.27375\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 0.46660828590393066, Avg Accuracy = 77.9375\n",
      "Epoch [10/150] :discriminator_loss=0.63907 target_loss=0.41618 discriminator_acc=0.65938\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 5.421848297119141, Avg Accuracy = 66.75000762939453\n",
      "Epoch [20/150] :discriminator_loss=0.64844 target_loss=0.46338 discriminator_acc=0.65521\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 6.832834720611572, Avg Accuracy = 66.75000762939453\n",
      "Epoch [30/150] :discriminator_loss=0.64583 target_loss=0.46220 discriminator_acc=0.66438\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 6.788212776184082, Avg Accuracy = 66.75000762939453\n",
      "Epoch [40/150] :discriminator_loss=0.64151 target_loss=0.46826 discriminator_acc=0.66542\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 7.453924655914307, Avg Accuracy = 66.75000762939453\n",
      "Epoch [50/150] :discriminator_loss=0.63595 target_loss=0.46861 discriminator_acc=0.66625\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 7.297560214996338, Avg Accuracy = 66.75000762939453\n",
      "Epoch [60/150] :discriminator_loss=0.63839 target_loss=0.47140 discriminator_acc=0.66500\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 7.405289649963379, Avg Accuracy = 66.75000762939453\n",
      "Epoch [70/150] :discriminator_loss=0.63623 target_loss=0.47017 discriminator_acc=0.66479\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 6.637790679931641, Avg Accuracy = 66.75000762939453\n",
      "Epoch [80/150] :discriminator_loss=0.62930 target_loss=0.46306 discriminator_acc=0.66479\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 7.013313293457031, Avg Accuracy = 66.75000762939453\n",
      "Epoch [90/150] :discriminator_loss=0.62818 target_loss=0.47493 discriminator_acc=0.66375\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 7.8917555809021, Avg Accuracy = 66.75000762939453\n",
      "Epoch [100/150] :discriminator_loss=0.62481 target_loss=0.47177 discriminator_acc=0.66104\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 7.711696147918701, Avg Accuracy = 66.75000762939453\n",
      "Epoch [110/150] :discriminator_loss=0.62114 target_loss=0.46706 discriminator_acc=0.66604\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Loss = 2.801046133041382, Avg Accuracy = 70.37500762939453\n",
      ">>> domain adaption <<<\n",
      "Avg Loss = 7.478940010070801, Avg Accuracy = 66.75000762939453\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b7f6281a69c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# # init weights of target encoder with those of source encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtgt_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtgt_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_tgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# # eval target encoder on test set of target dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a577b7c6aa85>\u001b[0m in \u001b[0;36mtrain_tgt\u001b[0;34m(src_encoder, tgt_encoder, critic)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0moptimizer_tgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mrun_tgt_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss_tgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mnum_batches\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m#######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load models\n",
    "src_encoder = Encoder_AMDA().to(device)\n",
    "\n",
    "src_classifier= Classifier().to(device)\n",
    "\n",
    "tgt_encoder = Encoder_AMDA().to(device)\n",
    "\n",
    "critic = Discriminator(input_dims=d_input_dims,\n",
    "                                  hidden_dims=d_hidden_dims,\n",
    "                                  output_dims=d_output_dims).to(device)\n",
    "\n",
    "# train source model\n",
    "\n",
    "print(\"=== Training classifier for source domain ===\")\n",
    "print(\">>> Source Encoder <<<\")\n",
    "print(src_encoder)\n",
    "print(\">>> Source Classifier <<<\")\n",
    "print(src_classifier)\n",
    "\n",
    "src_encoder, src_classifier = train_src(\n",
    "        src_encoder, src_classifier)\n",
    "\n",
    "# # eval source model\n",
    "print(\"=== Evaluating classifier for source domain ===\")\n",
    "eval_src(src_encoder, src_classifier)\n",
    "\n",
    "# # train target encoder by GAN\n",
    "print(\"=== Training encoder for target domain ===\")\n",
    "print(\">>> Target Encoder <<<\")\n",
    "print(tgt_encoder)\n",
    "print(\">>> Critic <<<\")\n",
    "print(critic)\n",
    "\n",
    "# # init weights of target encoder with those of source encoder\n",
    "tgt_encoder.load_state_dict(src_encoder.state_dict())\n",
    "tgt_encoder = train_tgt(src_encoder, tgt_encoder, critic)\n",
    "\n",
    "# # eval target encoder on test set of target dataset\n",
    "print(\"=== Evaluating classifier for encoded target domain ===\")\n",
    "print(\">>> source only <<<\")\n",
    "eval_tgt(src_encoder, src_classifier)\n",
    "print(\">>> domain adaption <<<\")\n",
    "eval_tgt(tgt_encoder, src_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix, Precision and Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedragab1992/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:162: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss = 2.312741994857788, Avg Accuracy = 9.979167938232422\n",
      "Avg Loss = 0.07230367511510849, Avg Accuracy = 99.52081298828125\n",
      "precision: 99.53821244782574 recall: 99.51991979131854 f-measure 99.52906527906067\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.954071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016701</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted label         0    1    2    3    4         5         6    7  \\\n",
       "Actual label                                                             \n",
       "0                1.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
       "1                0.000000  1.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
       "2                0.000000  0.0  1.0  0.0  0.0  0.000000  0.000000  0.0   \n",
       "3                0.000000  0.0  0.0  1.0  0.0  0.000000  0.000000  0.0   \n",
       "4                0.000000  0.0  0.0  0.0  1.0  0.000000  0.000000  0.0   \n",
       "5                0.002079  0.0  0.0  0.0  0.0  0.997921  0.000000  0.0   \n",
       "6                0.000000  0.0  0.0  0.0  0.0  0.029228  0.954071  0.0   \n",
       "7                0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  1.0   \n",
       "8                0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
       "9                0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
       "\n",
       "Predicted label         8    9  \n",
       "Actual label                    \n",
       "0                0.000000  0.0  \n",
       "1                0.000000  0.0  \n",
       "2                0.000000  0.0  \n",
       "3                0.000000  0.0  \n",
       "4                0.000000  0.0  \n",
       "5                0.000000  0.0  \n",
       "6                0.016701  0.0  \n",
       "7                0.000000  0.0  \n",
       "8                1.000000  0.0  \n",
       "9                0.000000  1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_domain=target_data_a.float()\n",
    "target_labels=target_labels_a.long()\n",
    "target_domain=target_data_b.float()\n",
    "target_labels=target_labels_b.long()\n",
    "target_domain=target_data_c.float()\n",
    "target_labels=target_labels_c.long()\n",
    "# target_domain=source_data.float()\n",
    "# target_labels=source_labels_0.long()\n",
    "\n",
    "eval_tgt(src_encoder, src_classifier)\n",
    "x,y=eval_tgt(tgt_encoder, src_classifier)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "pred = torch.LongTensor(2816, 5).cuda()\n",
    "torch.cat(x, out=pred)\n",
    "\n",
    "actual = torch.LongTensor(2816, 5).cuda()\n",
    "torch.cat(y, out=actual)\n",
    "\n",
    "pred=pred.cpu()\n",
    "actual=actual.cpu()\n",
    "con= confusion_matrix(actual.numpy(),pred.numpy(),labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "recall = np.diag(con) / np.sum(con, axis = 1)\n",
    "precision = np.diag(con) / np.sum(con, axis = 0)\n",
    "avg_recall=np.mean(recall)*100\n",
    "avg_precision=np.mean(precision)*100\n",
    "f_measure= 2*(avg_recall*avg_precision)/(avg_precision+avg_recall)\n",
    "con = con.astype('float') / con.sum(axis=1)[:, np.newaxis]\n",
    "conf = pd.DataFrame(data=con)\n",
    "conf.columns.name = 'Predicted label'\n",
    "conf.index.name = 'Actual label'\n",
    "print('precision:', avg_precision, 'recall:' , avg_recall, 'f-measure',f_measure)\n",
    "conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
